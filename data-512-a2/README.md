# DATA512 - A2: Bias in data

## Goal of the project
The [Wikipeida Detox project](https://meta.wikimedia.org/wiki/Research:Detox) aims to provide a better dicussion environment and has collected large hhuman-annotated 
datasets to train models to identify hostile language use on Wikipedia Talk page discussions. Google data scientists used these annotated datasets to train machine learning models as part of a project called [Conversation AI](https://github.com/conversationai/perspectiveapi). The models have been used in a variety of software products and made freely accessible to anyone through the Perspective API. 
<br>
<br>
For this assignment, the annotated Wikipeida Talk comments for aggression and toxicity are used to identify potential bias in human-labled and analyze implications of models trained using the labled data.
<br>
<br>
The labeled datasets can be downloaded from [Figshare](https://figshare.com/projects/Wikipedia_Talk/16731).
<br>
<br>



